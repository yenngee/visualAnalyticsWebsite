---
title: 'MC1: Explore relationships between Articles'
author: 'Ng Yen Ngee'
date: '2021-07-20'
lastmod: '2021-07-25'
slug: []
cover: "/img/explore_relationships.png"
categories: []
tags: ['MITB', "MC1", 'Text Analytics']
output:
  blogdown::html_page: 
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.retina = 3, 
                      echo=TRUE,
                      eval=TRUE,
                      message = FALSE,
                      warning = FALSE)
```

# Introduction 
In this post, I will be running through part 2b of [Vast Challenge MC1](https://vast-challenge.github.io/2021/MC1.html) which answers this question: What are the relationships between the primary and derivative sources? 

The final analysis done can be found [here](https://yenngee-dataviz.netlify.app/post/2021-07-16-mc1-findings/#1b-relationshipsprimary-vs-derivative-sources).


## Preperation 

### Import packages 

```{r load package}
library(tidyverse)
library(tidytext)
library(ggraph)
library(igraph)
library(widyr)
```

### Load Data 
The data has been previously loaded, cleaned and transformed into a neat tibble dataframe [here](https://yenngee-dataviz.netlify.app/post/2021-07-11-mc1-data-preperation/). 
We load the cleaned data directly below: 

```{r load_clean_text}
cleaned_text <- read_rds("data/news_article_clean.rds")
cleaned_text <- cleaned_text %>%
  mutate(title = tolower(title))
glimpse(cleaned_text)
```

### Tokenize Data
The process of the tokenizing the data is written in detail [here](https://yenngee-dataviz.netlify.app/post/2021-07-11-mc1-data-preperation/#tokenising). This is how the `token_words` look like. 

```{r token_stopwords, echo=FALSE}
custom_stop_words <- tribble(
  ~word, ~lexicon,
  "kronos", "CUSTOM",
  "abila",  "CUSTOM"
)
stop_words2 <- stop_words %>%
  bind_rows(custom_stop_words)

token_words <- cleaned_text %>% 
  unnest_tokens(word, text) %>%
  filter(str_detect(word, "[a-z']$"), # only keep words. exclude all numeric. 
         !word %in% stop_words2$word) # to remove stop words 
```

```{r token_words}
glimpse(token_words)
```

## Explore relationships 
### "Correlations" between articles
we want to know which newsgroup is more similar based on the words they use. 

```{r articles_cor}
words_by_articles <- token_words %>% 
  count(source, word, sort=TRUE) %>% 
  ungroup()

words_by_articles

articles_cors <- words_by_articles %>%
  pairwise_cor(source, word,n,sort=TRUE)

articles_cors
```

```{r cor_viz}
articles_cors%>% 
  arrange(desc(correlation)) %>%
  rowid_to_column('sort') %>%
  ggplot(aes(sort, correlation)) +
  geom_point()

articles_cors %>%
  filter(correlation > .65) %>%
  graph_from_data_frame() %>%
  ggraph(layout='fr') + 
  geom_edge_link(aes(alpha = correlation) , width = 1.5) + #alpha gives the shade
  geom_node_point(size=6, color="lightblue") +
  geom_node_text(aes(label=name), color="red", repel=TRUE) + 
  theme_void()
  
```

## ngrams
We look at words as consecutive terms. 

```{r bigram_viz}
bigrams <- cleaned_text %>%
  unnest_tokens(bigram, text, token = "ngrams", n=2)

bigrams_sep <- bigrams %>% 
  filter(bigram != 'NA') %>%
  separate(bigram, c("word1", "word2"), sep=" ")

bigrams_filtered <- bigrams_sep %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2%in% stop_words$word)%>%
  mutate(word = paste(word1, word2, sep=" "))

bigram_counts <- bigrams_filtered  %>%
  count(word, sort=TRUE) %>%
  filter(n>3)
bigram_counts

bigrams_by_articles <- bigrams_filtered %>% 
  count(source, word, sort=TRUE) %>% 
  ungroup()

bigrams_by_articles

articles_cors <- bigrams_by_articles %>%
  pairwise_cor(source, word,n,sort=TRUE)

articles_cors

articles_cors%>% 
  arrange(desc(correlation)) %>%
  rowid_to_column('sort') %>%
  ggplot(aes(sort, correlation)) +
  geom_point()

articles_cors %>%
  filter(correlation > .35) %>%
  graph_from_data_frame() %>%
  ggraph(layout='fr') + 
  geom_edge_link(aes(alpha = correlation) , width = 1.5) + #alpha gives the shade
  geom_node_point(size=6, color="lightblue") +
  geom_node_text(aes(label=name), color="red", repel=TRUE) + 
  theme_void()
```